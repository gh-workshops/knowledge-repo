{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Reading Meetups from IBM Cloudant using Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be the second in our series, we are going to utilize the [Apache Spark](http://spark.apache.org/) and [Cloudant](https://cloudant.com/) [Bluemix](https://console.ng.bluemix.net/) services to read data into Spark Dataframes from our IBM Cloudant Bluemix service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please reference the first notebook in our series, [Streaming Meetups to IBM Cloudant using Spark](https://github.com/ibm-et/jupyter-samples/blob/master/bluemix-spark-cloudant/1-Streaming-Meetups-to-IBM-Cloudant-using-Spark.ipynb), for a detailed list of prerequisites to get up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Add Dependencies/Jars\n",
    "In order to run this demonstration notebook we are using the cloudant-spark library. These scala dependencies/jars are added to our environment using the AddJar magic from the Spark Kernel, which adds the specified jars to the Spark Kernel and Spark cluster.\n",
    "* cloudant-spark - Allows us to perform Spark SQL queries against RDDs backed by Cloudant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached version of cloudant-spark.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar https://dl.dropboxusercontent.com/u/19043899/cloudant-spark.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize spark context with cloudant configurations\n",
    "The Bluemix Apache Spark service notebook comes with a spark context ready to use, but we are going to have to modify this one to configure built in support for cloudant.  Note for the demo purposes we are setting the spark master to run in local mode, but by default the Spark service will run in cluster mode.  Update the HOST, USERNAME, and PASSWORD below with the credentials to connect to your Bluemix Cloudant service which our demo depends on.  You can get these credentials from the Palette on the right by clicking on the Data Source option.  If your data source does not exist add it using the Add Source button or if it already does you can use the \"Insert to code\" button to add the information to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.{DataFrame, SQLContext}\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.apache.spark.streaming.{Time, Seconds, StreamingContext}\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "\n",
    "val conf = sc.getConf\n",
    "conf.set(\"cloudant.host\",\"HOST\")\n",
    "conf.set(\"cloudant.username\", \"USERNAME\")\n",
    "conf.set(\"cloudant.password\",\"PASSWORD\")\n",
    "\n",
    "conf.setJars(ClassLoader.getSystemClassLoader.asInstanceOf[java.net.URLClassLoader].getURLs.map(_.toString).toSet.toSeq ++ kernel.interpreter.classLoader.asInstanceOf[java.net.URLClassLoader].getURLs.map(_.toString).toSeq)\n",
    "conf.set(\"spark.driver.allowMultipleContexts\", \"true\")\n",
    "conf.set(\"spark.master\",\"local[*]\")\n",
    "val scCloudant = new SparkContext(conf)\n",
    "scCloudant.getConf.getAll.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read from the IBM Cloudant Bluemix service\n",
    "Using the cloudant-spark library we are able to seemlessly interact with our IBM Cloudant Bluemix Service meetup_group database through the abstraction of Spark Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFromDatabase(sqlContext: SQLContext, databaseName: String) = {\n",
    "    val df = sqlContext.read.format(\"com.cloudant.spark\").load(databaseName)\n",
    "    df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Read from IBM Cloudant and filter on our dataframe\n",
    "First we must create an SQL context from our Spark context we created in step 2.  We can then simply use our readFromDatabase function previously defined to perform Spark Dataframe operations such as filtering on fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use dbName=meetup_group, indexName=null, jsonstore.rdd.partitions=5, jsonstore.rdd.maxInPartition=-1, jsonstore.rdd.minInPartition=10, jsonstore.rdd.requestTimeout=100000,jsonstore.rdd.concurrentSave=-1,jsonstore.rdd.bulkSize=1\n",
      "+--------------------+--------------------+----------+-------------+--------+---------+---------+--------------------+-----------+--------------------+--------------------+\n",
      "|                 _id|                _rev|group_city|group_country|group_id|group_lat|group_lon|          group_name|group_state|        group_topics|       group_urlname|\n",
      "+--------------------+--------------------+----------+-------------+--------+---------+---------+--------------------+-----------+--------------------+--------------------+\n",
      "|1d335ff5eb23f7f00...|1-acea197c65b80be...|Richardson|           us|15196832|    32.96|   -96.75|Richardson/Plano ...|         TX|List([Referral Ma...|RichardsonPlanoNe...|\n",
      "|1d335ff5eb23f7f00...|1-72d2c8a62057bcd...|    Austin|           us|18179233|    30.24|   -97.76|Doodle Crew USA :...|         TX|List([Cartoonists...|     Doodle-Dudes-TX|\n",
      "|2c9d4bb8ad5eaa34f...|1-bbc4604e3e53946...|    Spring|           us|18652297|    30.14|   -95.47|Spring/Woodlands ...|         TX|List([Dining Out,...|Spring-Woodlands-...|\n",
      "|2c9d4bb8ad5eaa34f...|1-ec2d7e34afb7173...|    Austin|           us| 5256562|    30.24|   -97.76|Austin Associatio...|         TX|List([Investing,i...|Austin-Associatio...|\n",
      "|2c9d4bb8ad5eaa34f...|1-acea197c65b80be...|Richardson|           us|15196832|    32.96|   -96.75|Richardson/Plano ...|         TX|List([Referral Ma...|RichardsonPlanoNe...|\n",
      "+--------------------+--------------------+----------+-------------+--------+---------+---------+--------------------+-----------+--------------------+--------------------+\n",
      "\n",
      "+--------------------+--------------------+----------+-------------+--------+---------+---------+--------------------+-----------+--------------------+--------------------+\n",
      "|                 _id|                _rev|group_city|group_country|group_id|group_lat|group_lon|          group_name|group_state|        group_topics|       group_urlname|\n",
      "+--------------------+--------------------+----------+-------------+--------+---------+---------+--------------------+-----------+--------------------+--------------------+\n",
      "|1d335ff5eb23f7f00...|1-72d2c8a62057bcd...|    Austin|           us|18179233|    30.24|   -97.76|Doodle Crew USA :...|         TX|List([Cartoonists...|     Doodle-Dudes-TX|\n",
      "|2c9d4bb8ad5eaa34f...|1-ec2d7e34afb7173...|    Austin|           us| 5256562|    30.24|   -97.76|Austin Associatio...|         TX|List([Investing,i...|Austin-Associatio...|\n",
      "|2c9d4bb8ad5eaa34f...|1-b07f0f605694ffc...|    Austin|           us| 7894862|    30.26|   -97.87|  Dance Walk! Austin|         TX|List([New In Town...|   Dance-Walk-Austin|\n",
      "|39cc2df929299bb06...|1-f1b6882f0b1912a...|    Austin|           us| 3648022|    30.27|   -97.74|Austin Geeks and ...|         TX|List([Doctor Who,...|AustinGeeksandGamers|\n",
      "|39cc2df929299bb06...|1-ee5bc44c0904ece...|    Austin|           us| 1758659|    30.27|   -97.74|AWESOME AUSTIN! I...|         TX|List([Dining Out,...|         AustinTexas|\n",
      "+--------------------+--------------------+----------+-------------+--------+---------+---------+--------------------+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val sqlContext = new SQLContext(scCloudant)\n",
    "import sqlContext.implicits._\n",
    "val df = readFromDatabase(sqlContext, \"meetup_group\")\n",
    "df.show(5)\n",
    "df.filter(df(\"group_city\")===\"Austin\").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10",
   "language": "scala",
   "name": "spark"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}